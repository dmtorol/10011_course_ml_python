{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción teórica a la regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Ecuaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística es un método supervisado de clasificación que está basado en la regresión lineal. El objetivo de este método es obtener a partir de un predictor que puede tomar cualquier rango de valores, una predicción de tipo dicotómica (clasificación). Ejemplos de este tipo de análisis podrían ser:\n",
    "\n",
    "- Inferir si un tumor es benigno o maligno en base a una serie de características como tamaño...etc\n",
    "- Diferenciar si un email es spam o no en en función del remitente, contenido...etc\n",
    "\n",
    "Para llevar a cabo este modelo, es necesario tranformar la ecuación de la regresión para que en vez de obtener un resultado cuantitativo continuo, nos de una variable binaria.\n",
    "\n",
    "> *Indicar que aunque es un método de clasificación con un resultado binario, la regresión logística lo que en verdad nos dice es la probabilidad de pertenecer a un grupo u otro, y en base a esa probabilidad podremos establecer un umbral (threshold) que defina a que clase pertenece cada observación.*\n",
    "\n",
    "Aunque en primera instancia se puede pensar que para realizar este ejercicio se podría utilizar una regresión lineal en la que los resultados estuvieran dicotomizados entre 0 y 1, al modelizar esta recta de regresión, la cual por su naturaleza tiene un dominio $f(x) \\in [-\\infty, +\\infty]$, podríamos encontrar valores/probabilidades por encima de 1 o por debajo de 0  los valores extremos, lo cual matemáticamente sería incorrecto si estamos tratando de obtener una probabilidad.\n",
    "\n",
    "Para resolver este problema, se le hace una serie de tranformaciones a la ecuación de regresión lineal para que su dominio siempre pertenezaca al intervalo $f(x) \\in [0, 1]$. Esta tranformación relaciona el concepto de probabilidad de ocurrencia de un suceso, con la ecuación de la recta.\n",
    "\n",
    "La probabilidad de que ocurra un suceso se define como la razón entre los sucesos favorables y los sucesos totales:\n",
    "\n",
    "\\begin{align}\n",
    "P(y = suceso\\ favorable \\ |\\ x) = \\frac{sucesos\\ favorables}{sucesos\\ totales}\\qquad P \\in [0, 1]\n",
    "\\end{align}\n",
    "\n",
    "La razón de probabilidad (odds ratio) de un suceso favorable se define como el ratio entre la probabilidad del suceso favorable y la probabilidad del suceso desfavorable (1-P):\n",
    "\n",
    "\\begin{align}\n",
    "odds = \\frac{P}{1-P}\\qquad odds \\in [0, +\\infty]\n",
    "\\end{align}\n",
    "\n",
    "Dado que en este momento nos encontramos trabajando en el rango $[0, +\\infty]$, aplicamos a la expresión anterior la función *logit*, que consiste en aplicar el logaritmo natural a la razón de probabilidad. Dado que el logaritmo neperiano de 0 tiene al valor infinito negativo, ya tendríamos el rango buscado:\n",
    "\n",
    "\\begin{align}\n",
    "ln(odds) = ln\\Bigl(\\frac{P}{1-P}\\Bigr)\\qquad ln(odds) \\in [-\\infty, +\\infty]\n",
    "\\end{align}\n",
    "\n",
    "Una vez tenemos ambas expresiones en el mismo rango $[-\\infty, +\\infty]$, podemos relacionar el log of odds con la ecuación de la regresión lineal:\n",
    "\n",
    "\\begin{align}\n",
    "ln\\Bigl(\\frac{P}{1-P}\\Bigr) = \\beta_0 + \\beta_1 x \\ \\Rightarrow \\ P = \\hat{y} = \\frac{1}{1+e^{-(\\beta_0 + \\beta_1 x)}}\n",
    "\\end{align}\n",
    "\n",
    "Tenemos por lo tanto una predicción que sigue la forma de una función denominada logística o sigmoide. Para esta función, cuando los valores de $x$ son muy grandes, el término $e^{-(\\beta_0 + \\beta_1 x)}$ tiende a 0, por lo que la probabilidad o predicción tenderá a 1; y en caso de que el denominador sea pequeño, la función tenderá a 0.\n",
    "\n",
    "En el caso de trabajar con una regresión logística múltiple el proceso sería muy parecido, solo que los términos $X$ y $\\beta$ serán vectores.\n",
    "\n",
    "\\begin{align}\n",
    "P = \\hat{y} = \\frac{1}{1+e^{-(\\beta_0 + \\sum \\beta_p x_{np})}} = \\frac{1}{1+e^{-(X \\beta)}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Coeficientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se ha definido la ecuación predictora del modelo, es necesario estimar los coeficines $\\alpha$ y $\\beta$. Estos parámetros se pueden obtener mediante el método de la máxima verosimiliutd (ML - Maximum Likelihood) o por el algoritmo del gradiente descendente. En este notebook se explicará el primero de ellos.\n",
    "\n",
    "El objetivo del método de la máxima verosimilitud, es obtener unos valores estimados de $\\hat{\\alpha}$ y $\\hat{\\beta}$ que introducidos en el modelo de predicción $\\hat{y}$ nos den un valor lo más cercano a 1 para aquellos valores del dataset que vienen con valor 1,  y un valor cercano a 0 para aquellos registros del dataset con la variable dependiente igual a 0. Esto anterior se puede formalizar usando una ecuación matemática denominada función de verosimilitud (likelihood function):\n",
    "\n",
    "\\begin{align}\n",
    "L(\\alpha, \\beta) = \\prod P(x_i)^{y_i}(1-P(x_i))^{1-y_i}\n",
    "\\end{align}\n",
    "\n",
    "Tomando logaritmos en la expresión anterior para simplificarla y sustituyendo $P(x_i)$:\n",
    "\n",
    "\\begin{align}\n",
    "l = ln(L(\\alpha, \\beta)) = \\sum_{i=1}^{n} -ln(1+e^{X\\beta}) + y_i(\\beta_0 + \\sum_{j=p}^{n} \\beta_j X_{ij})\n",
    "\\end{align}\n",
    "\n",
    "Para buscar los estimadores de máxima verosimilutd se deriva la expresión y se iguala a cero. Para unir las dos expresiones siguientes en una única, se igual el coeficiente $\\alpha$ a uno nuevo denominado $\\beta_0$, y se añade un término nuevo $x_{i0}$ = 1:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial l}{\\partial \\alpha} = \\sum(y_i - P(x_i)) = 0 \\ ;\\quad\n",
    "\\frac{\\partial l}{\\partial \\beta_j} = \\sum (y_i - P(x_i))x_{ij} = 0\\quad \\rightarrow \\quad\n",
    "\\frac{\\partial l}{\\partial \\beta} = \\sum (y_i - P(x_i))x_{ij} = X· (y_i - P(x_i)) = 0\n",
    "\\end{align}\n",
    "\n",
    "Como el resultado de las derivadas pueden ser una serie de ecuaciones que no tengan una solución sencilla, se puede recurrir al método de Newton-Raphson. Este algoritmo permite encontrar aproximaciones de los ceros o raíces de una función real y también puede ser usado para encontrar el máximo o mínimo de una función, encontrando los ceros de su primera derivada.\n",
    "\n",
    "\\begin{align}\n",
    "\\beta_{n+1} = \\beta_n - \\varDelta \\beta \\quad \\rightarrow \\quad\n",
    "\\varDelta \\beta = \\frac{f(\\beta)}{f'(\\beta)} = \\frac{\\frac{\\partial l}{\\partial \\beta}}{\\frac{\\partial^2 l}{\\partial \\beta^2}} = \n",
    "(XWX^T)·(X(y-P_i)) \\quad \\rightarrow \\quad W(\\beta) = diag(P(x_i)(1-P(x_i)))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los modelos logísticos no existe un indicador de la bondad de los resultados como el $R^2$ que determina la varianza del modelo. Mediante las diferentes funciones estadísticas de paquetes como `statsmodel`, se puede obterner el indicador $pseudo-R^2$. Este indicador nos da una estimación entre 0 y 1 de la precisión del modelo, pero no se puede considerar equivalente al $R^2$.\n",
    "\n",
    "Otras formas de evaluar el ajuste del modelo puede ser obteniendo el porcentaje de aciertos, y diferenciándolos entre falsos positivos, falsos negativos...etc, y representar estos datos mediante una matriz de confusión.\n",
    "\n",
    "La precisión *(precision)* es la capacidad del clasificador de no etiquetar una muestra como positiva si es negativa. Su fórmula es:\n",
    "\n",
    "\\begin{align}\n",
    "precision = \\frac{tp}{tp+fp}\\qquad\n",
    "\\end{align}\n",
    "\n",
    "La recuperación *(recall)* es la capacidad del clasificador para encontrar todas las muestras positivas. Su fórmula es:\n",
    "\n",
    "\\begin{align}\n",
    "recall = \\frac{tp}{tp+fn}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regresión logística - statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statsmodels es una librería de Python que proporciona clases y funciones para la estimación de muchos modelos estadísticos diferentes, así como para realizar pruebas estadísticas y exploración de datos estadísticos.\n",
    "\n",
    "Este paquete permite obtener datos estadísticos y las bondades de ajuste de una regresión logística y también permite analizar que variables tienen más peso en el ajuste del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos librerias\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio vamos a utilizar un dataset que contiene información de las diferentes campañas de marketing de una entidad bancaria portuguesa, el objetivo es inferir si el cliente se suscribirá o no al producto vendido (variable y - un depósito) en base al resto de datos del fichero.\n",
    "\n",
    "El fichero original tiene información de 41.118 registros, y 21 columnas. Para ahorrar en este notebook toda la parte de limpieza de datos, las variables ya vienen dumificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>...</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>346</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  duration  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0   30       487         2    999         0          -1.8          92.893   \n",
       "1   39       346         4    999         0           1.1          93.994   \n",
       "2   25       227         1    999         0           1.4          94.465   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  ...  month_oct  month_sep  \\\n",
       "0          -46.2      1.313       5099.1  ...          0          0   \n",
       "1          -36.4      4.855       5191.0  ...          0          0   \n",
       "2          -41.8      4.962       5228.1  ...          0          0   \n",
       "\n",
       "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
       "0                1                0                0                0   \n",
       "1                1                0                0                0   \n",
       "2                0                0                0                0   \n",
       "\n",
       "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \n",
       "0                0                 0                     1                 0  \n",
       "1                0                 0                     1                 0  \n",
       "2                1                 0                     1                 0  \n",
       "\n",
       "[3 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cargamos el fichero de trabajo\n",
    "mainpath = \"C:/Users/gmachin/Desktop/Developer/apuntes-notebooks/datasets\"\n",
    "filename = \"/bank/bank.csv\"\n",
    "fullpath = mainpath + filename\n",
    "\n",
    "df_bank = pd.read_csv(fullpath)\n",
    "\n",
    "df_bank.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el dataset cargado, definimos las variables predictoras $X$, y la variable dependiente o a predecir $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Los predictores serán todas las columnas de la tabla menos la columna 'y'\n",
    "X = df_bank.drop(['y'], axis = 1)\n",
    "\n",
    "## En este dataset ya viene la columna a predecir nombrada con la letra 'y'\n",
    "y = df_bank[['y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elección de predictores:**\n",
    "\n",
    "El próximo paso es decidir de entre las 58 variables predictoras que contiene este dataset, cuales tendrán más peso en el modelo. Para ello se emplea la funcion `.RFE` (Recursive Feature Elimination) de la librería `scikit-learn`.\n",
    "\n",
    "La eliminación de características recursivas (RFE) se basa en la idea de construir repetidamente un modelo y elegir las características con mejor o peor desempeño, dejando a un lado una característica y luego repitiendo el proceso con el resto de las características. Este proceso se aplica hasta que se agoten todas las características del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets                             \n",
    "from sklearn.feature_selection import RFE                 ## Importamos la función RFE\n",
    "from sklearn.linear_model import LogisticRegression       ## Importamos modelo de regresión logística\n",
    "\n",
    "## Indicamos número de variables predictoras (libre albedrío)\n",
    "n = 12\n",
    "\n",
    "## Creamos un objeto de regresión logística\n",
    "lr = LogisticRegression()\n",
    "\n",
    "## Creamos un objeto rfe e indicamos como parámetros que es una regresión logística, y el número de predictores\n",
    "rfe = RFE(lr, n)\n",
    "\n",
    "## Alimentamos el modelo rfe con los valores de X y de y para entrenarlo\n",
    "rfe = rfe.fit(X, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la función `.support_` del objeto `rfe` creado, se puede obtener que predictores son los mejores para realizar la regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True False False False  True False False False\n",
      "  True False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True  True  True  True  True False\n",
      "  True False False False False False False  True False  True]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede obtener el ranking de los mejores predictores mediante la función `.ranking_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34 40 18 42  1 14 27 25  1 38 22  3  1 35  2 36  1  5 30 33 12 45 19 39\n",
      " 31 47 26 13 46 21 32  8 20  6 10 15  9 23 16  4 43 24  1  1  1  1  1 17\n",
      "  1 44 37 28 41 29 11  1  7  1]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver definitivamente que columnas se van a utilizar, podemos juntar las 3 listas anteriores: nombre de las columnas, resultado de la función `.support_` y resultado de la función `.ranking_`. Aquellas que tengan el valor True y el número 1 serán las incluídas en el modelo como predictores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', False, 34),\n",
       " ('duration', False, 40),\n",
       " ('campaign', False, 18),\n",
       " ('pdays', False, 42),\n",
       " ('previous', True, 1),\n",
       " ('emp.var.rate', False, 14),\n",
       " ('cons.price.idx', False, 27),\n",
       " ('cons.conf.idx', False, 25),\n",
       " ('euribor3m', True, 1),\n",
       " ('nr.employed', False, 38),\n",
       " ('y', False, 22),\n",
       " ('job_admin.', False, 3),\n",
       " ('job_blue-collar', True, 1),\n",
       " ('job_entrepreneur', False, 35),\n",
       " ('job_housemaid', False, 2),\n",
       " ('job_management', False, 36),\n",
       " ('job_retired', True, 1),\n",
       " ('job_self-employed', False, 5),\n",
       " ('job_services', False, 30),\n",
       " ('job_student', False, 33),\n",
       " ('job_technician', False, 12),\n",
       " ('job_unemployed', False, 45),\n",
       " ('job_unknown', False, 19),\n",
       " ('marital_divorced', False, 39),\n",
       " ('marital_married', False, 31),\n",
       " ('marital_single', False, 47),\n",
       " ('marital_unknown', False, 26),\n",
       " ('education_Basic', False, 13),\n",
       " ('education_High School', False, 46),\n",
       " ('education_Illiterate', False, 21),\n",
       " ('education_Professional Course', False, 32),\n",
       " ('education_University Degree', False, 8),\n",
       " ('education_Unknown', False, 20),\n",
       " ('housing_no', False, 6),\n",
       " ('housing_unknown', False, 10),\n",
       " ('housing_yes', False, 15),\n",
       " ('loan_no', False, 9),\n",
       " ('loan_unknown', False, 23),\n",
       " ('loan_yes', False, 16),\n",
       " ('contact_cellular', False, 4),\n",
       " ('contact_telephone', False, 43),\n",
       " ('month_apr', False, 24),\n",
       " ('month_aug', True, 1),\n",
       " ('month_dec', True, 1),\n",
       " ('month_jul', True, 1),\n",
       " ('month_jun', True, 1),\n",
       " ('month_mar', True, 1),\n",
       " ('month_may', False, 17),\n",
       " ('month_nov', True, 1),\n",
       " ('month_oct', False, 44),\n",
       " ('month_sep', False, 37),\n",
       " ('day_of_week_fri', False, 28),\n",
       " ('day_of_week_mon', False, 41),\n",
       " ('day_of_week_thu', False, 29),\n",
       " ('day_of_week_tue', False, 11),\n",
       " ('day_of_week_wed', True, 1),\n",
       " ('poutcome_failure', False, 7),\n",
       " ('poutcome_nonexistent', True, 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank_vars = df_bank.columns.values.tolist()\n",
    "z = zip(df_bank_vars, rfe.support_, rfe.ranking_)\n",
    "\n",
    "list(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creamos una lista con todas las columnas con valor True del modelo RFE\n",
    "cols = [\"previous\", \"euribor3m\", \"job_blue-collar\", \"job_retired\", \"month_aug\", \"month_dec\", \n",
    "        \"month_jul\", \"month_jun\", \"month_mar\", \"month_nov\", \"day_of_week_wed\", \"poutcome_nonexistent\"]\n",
    "\n",
    "X = df_bank[cols]\n",
    "y = df_bank[[\"y\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de regresión logística múltiple:**\n",
    "\n",
    "Mediante la función `sm.Logit(output, inputs).fit()` de `statsmodel`, se puede obtener el modelo de regresión logística de una variable dependiente $y$ frente a las variables independientes $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.291770\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de los coeficientes:**\n",
    "\n",
    "Una vez se ha creado el modelo, se puede obtener el valor de cada parámetro $\\beta$ mediante la función `.params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "previous               -0.122862\n",
       "euribor3m              -0.604899\n",
       "job_blue-collar        -0.503233\n",
       "job_retired             0.223547\n",
       "month_aug               0.604806\n",
       "month_dec               1.135775\n",
       "month_jul               1.032700\n",
       "month_jun               1.077547\n",
       "month_mar               1.644831\n",
       "month_nov               0.382789\n",
       "day_of_week_wed        -0.064885\n",
       "poutcome_nonexistent   -0.775330\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto en temas anteriores, estos coeficientes son estimados, y por lo tanto debemos calcular su p-valor para ver si estos parámetros tienen significancia estadística. Marcamos como nivel de significancia válido 0.05.\n",
    "\n",
    "Se pueden obtener los p-valores mediante la función `.pvalues`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "previous                7.934286e-02\n",
       "euribor3m               3.749001e-56\n",
       "job_blue-collar         9.209968e-04\n",
       "job_retired             3.074857e-01\n",
       "month_aug               5.872384e-04\n",
       "month_dec               1.146942e-02\n",
       "month_jul               6.406993e-08\n",
       "month_jun               7.784547e-10\n",
       "month_mar               1.599367e-07\n",
       "month_nov               4.959867e-02\n",
       "day_of_week_wed         6.408835e-01\n",
       "poutcome_nonexistent    2.164260e-10\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo:**\n",
    "\n",
    "Por último se puede presentar un cuadro resumen de todos los indicadores y valores estadísticos del modelo mediante la función `.summary()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>  4119</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4107</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 19 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1554</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:57:13</td>     <th>  Log-Likelihood:    </th> <td> -1201.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1422.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>6.449e-88</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous</th>             <td>   -0.1229</td> <td>    0.070</td> <td>   -1.755</td> <td> 0.079</td> <td>   -0.260</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>euribor3m</th>            <td>   -0.6049</td> <td>    0.038</td> <td>  -15.788</td> <td> 0.000</td> <td>   -0.680</td> <td>   -0.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>job_blue-collar</th>      <td>   -0.5032</td> <td>    0.152</td> <td>   -3.314</td> <td> 0.001</td> <td>   -0.801</td> <td>   -0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>job_retired</th>          <td>    0.2235</td> <td>    0.219</td> <td>    1.021</td> <td> 0.307</td> <td>   -0.206</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_aug</th>            <td>    0.6048</td> <td>    0.176</td> <td>    3.437</td> <td> 0.001</td> <td>    0.260</td> <td>    0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_dec</th>            <td>    1.1358</td> <td>    0.449</td> <td>    2.528</td> <td> 0.011</td> <td>    0.255</td> <td>    2.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_jul</th>            <td>    1.0327</td> <td>    0.191</td> <td>    5.407</td> <td> 0.000</td> <td>    0.658</td> <td>    1.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_jun</th>            <td>    1.0775</td> <td>    0.175</td> <td>    6.149</td> <td> 0.000</td> <td>    0.734</td> <td>    1.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_mar</th>            <td>    1.6448</td> <td>    0.314</td> <td>    5.241</td> <td> 0.000</td> <td>    1.030</td> <td>    2.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_nov</th>            <td>    0.3828</td> <td>    0.195</td> <td>    1.963</td> <td> 0.050</td> <td>    0.001</td> <td>    0.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day_of_week_wed</th>      <td>   -0.0649</td> <td>    0.139</td> <td>   -0.466</td> <td> 0.641</td> <td>   -0.338</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poutcome_nonexistent</th> <td>   -0.7753</td> <td>    0.122</td> <td>   -6.349</td> <td> 0.000</td> <td>   -1.015</td> <td>   -0.536</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 4119\n",
       "Model:                          Logit   Df Residuals:                     4107\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Tue, 19 May 2020   Pseudo R-squ.:                  0.1554\n",
       "Time:                        19:57:13   Log-Likelihood:                -1201.8\n",
       "converged:                       True   LL-Null:                       -1422.9\n",
       "Covariance Type:            nonrobust   LLR p-value:                 6.449e-88\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "previous                -0.1229      0.070     -1.755      0.079      -0.260       0.014\n",
       "euribor3m               -0.6049      0.038    -15.788      0.000      -0.680      -0.530\n",
       "job_blue-collar         -0.5032      0.152     -3.314      0.001      -0.801      -0.206\n",
       "job_retired              0.2235      0.219      1.021      0.307      -0.206       0.653\n",
       "month_aug                0.6048      0.176      3.437      0.001       0.260       0.950\n",
       "month_dec                1.1358      0.449      2.528      0.011       0.255       2.016\n",
       "month_jul                1.0327      0.191      5.407      0.000       0.658       1.407\n",
       "month_jun                1.0775      0.175      6.149      0.000       0.734       1.421\n",
       "month_mar                1.6448      0.314      5.241      0.000       1.030       2.260\n",
       "month_nov                0.3828      0.195      1.963      0.050       0.001       0.765\n",
       "day_of_week_wed         -0.0649      0.139     -0.466      0.641      -0.338       0.208\n",
       "poutcome_nonexistent    -0.7753      0.122     -6.349      0.000      -1.015      -0.536\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si analizamos los p-valores, encontramos que existen 4 parámetros cuyo valor supera el 0.05, por lo que podríamos eliminarlos del modelo por no tener significancia estadística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se ha dado por bueno el modelo de predicción obtenido, también se pueden obtener las variables dependientes $\\hat{y}_i$ a partir de las variables independientes $X$ mediante la función `lm.predict(pd.DataFrame(inputs))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regresión logística - scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn es una libreria de aprendizaje automático de software libre para el lenguaje de programación Python. Incluye algoritmos de clasificación, regresión y clustering.\n",
    "\n",
    "Al igual que el paquete statsmodel, esta librería contiene ya funciones predefinidas que permiten realizar una regresión logística de forma sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos librerias\n",
    "from sklearn.linear_model import LinearRegression              ## Módulo para realizar regresiones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de regresión lineal múltiple:**\n",
    "\n",
    "Para fabricar el módelo de regresión mediante la libreria `scikit-learn` en primer lugar se debe crear un objeto de regresión logística mediante la función `LogisticRegression()`, para después entrenarlo con el dataset `.fit(inputs, outputs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crear un objeto de regresión lineal, lo llamamos logit_model:\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "## Entrenamiento del modelo mediante el dataset:\n",
    "logit_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de los coeficientes:**\n",
    "\n",
    "Una vez se ha entrenado el modelo, se pueden extraer los coeficientes \\beta mediante la función `.coef_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50765714, -0.54649613, -0.35915536,  0.35603839,  0.62539831,\n",
       "         1.1822173 ,  0.96226336,  1.05431792,  1.63063663,  0.45195768,\n",
       "         0.04171434,  0.30569877]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *El valor de los coeficientes puede variar ligeramente si se comparan con los obtenidos a partir de la librería `statsmodel`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo:**\n",
    "\n",
    "Podemos obtener el indicador de precisión del modelo mediante la función `lm.score(inputs, outputs)`. Este indicador lo que comprueba es si el valor predecido es igual o no a la variable dependiente, y muestra el porcentaje de acierto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963340616654528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se ha dado por bueno el modelo de predicción obtenido, también se pueden obtener las variables dependientes $\\hat{y}_i$ a partir de las variables independientes $x_i$ mediante la función `.predict(inputs)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo - conjunto de test y entrenamiento:**\n",
    "\n",
    "Aunque en los puntos anteriores hemos obtenido los coeficientes y bondad de ajuste del modelo a partir de todo el conjunto de datos, los normal es dividir el fichero en dos subconjuntos. El primero de ellos será para el entrenamiento del modelo y suele ser de entre el 70-80% del dataset, y dejar el resto para testear el modelo.\n",
    "\n",
    "Este método evita los problemas de overfitting que se darían si utilizasemos todo el dataset como conjunto de entrenamiento.\n",
    "\n",
    "Para dividir un dataset en conjunto de test y en conjunto de entrenamiento, podemos utilizar la función `.train_test_split(inputs, outputs, test_size, random_state)` de la librería `scikit-learn`.\n",
    "\n",
    "- `inputs`: variables predictoras\n",
    "- `outputs`: variable dependiente\n",
    "- `test_size`: % del dataset que se va a utilizar como subconjunto de test\n",
    "- `random_state`: seed de los número aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos la función train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Indicamos que queremos un subconjunto de test de un 30%, y una semilla con valor 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "## Crear un objeto de regresión lineal, lo llamamos logit_model:\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "## Entrenamiento del modelo mediante el dataset de entrenamiento:\n",
    "logit_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el modelo entrenado, podemos obtener la bondad de ajuste del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004854368932039"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importamos la función metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "## Realizamos la predicción a partir de las variables de test\n",
    "prediction = logit_model.predict(X_test)\n",
    "\n",
    "## Evaluamos la precisión para el subconjunto de test\n",
    "metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo - validación cruzada:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada (cross validation) es una técnica utilizada para evaluar los resultados del análisis estadístico son independientes de las particiones entre subconjuntos de test y entrenamiento.\n",
    "\n",
    "Esta técnica divide un dataset en subconjunto de test y entrenamiento de k-formas diferentes, y para cada una de estas formas calcula todos los parámetros. Por último se hace la media aritmética de los parámetros de cada validación, y se obtiene una media de los datos. Este método disminuye errores en la estimación de parámetros de cada modelo, y minimiza otras casuísticas como el overfitting.\n",
    "\n",
    "Dentro del método de validación cruzada, en función del número k en el que dividamos el dataset podemos definir 3 métodos:\n",
    "\n",
    "- k = 1: validación cruzada simple\n",
    "- k = 5-10: K-fold cross validation\n",
    "- k = n: Leave One Out Cross Validation (LOOCV)\n",
    "\n",
    "En función del valor de k, podremos experimentar una compensación del sesgo-varianza, teniendo para valores de k muy elevadas, modelos con un sesgo bajo pero con una varianza muy elevada, es decir overfitting. En bibliografía de referencia como *An Introduction to Statistical Learning*, se recomienda utilizar el método k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos la función cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## Dividimos el dataset en 10 folders\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring = \"accuracy\", cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9031477 , 0.88834951, 0.90533981, 0.89563107, 0.90048544,\n",
       "       0.8907767 , 0.88349515, 0.89320388, 0.89537713, 0.88807786])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Obtenemos el score de cada folder\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8943884240990478"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
