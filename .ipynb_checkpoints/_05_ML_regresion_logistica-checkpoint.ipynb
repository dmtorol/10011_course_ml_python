{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción teórica a la regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística es un método supervisado de clasificación que está basado en la regresión lineal. El objetivo de este método es obtener a partir de una serie de predictores que pueden tomar cualquier rango de valores, una predicción de tipo dicotómica (clasificación). Ejemplos de este tipo de análisis podrían ser:\n",
    "\n",
    "- Inferir si un tumor es benigno o maligno en base a una serie de características como: tamaño, volumen, color...etc\n",
    "- Diferenciar si un email es spam o no en en función de: remitente, contenido...etc\n",
    "\n",
    "Aunque es un método de clasificación, está basado en la regresión lineal, por lo que para llevar a cabo este modelo es necesario tranformar la ecuación regresión. Esta transformación permite obtener como resultado una variable con un valor binario en vez de un valor cuantitativo continuo.\n",
    "\n",
    "> *Indicar que aunque es un método de clasificación con un resultado binario, la regresión logística lo que en verdad indica es la probabilidad de pertenecer a un grupo u otro, y en base a esa probabilidad podremos establecer un umbral (threshold) que defina a que clase pertenece cada observación.*\n",
    "\n",
    "La regresión logística es un algoritmo que solo permite obtener un clasificación de tipo dicotómica, es decir, o 1 o 0. Pero existen algunos métodos para adaptar este algoritmo y poder realizar clasificaciones en más categorías:\n",
    "\n",
    "- Uno contra todos (one-vs.-all, OvA): En esta estrategia se ha de entrenar tantos clasificadores binarios como clases existan en el conjunto de datos. Cada uno de los modelos predice la probabilidad de que el registro pertenezca a una clase. A la hora de realizar una predicción se ejecutan todos los clasificadores y se selecciona aquel que ofrece mayor probabilidad.\n",
    "\n",
    "- Uno contra uno (one-vs.-one, OvO): En esta estrategia se crean tantos modelos como pares de posibles resultados existan. Es decir, se han de entrenar $(N^2-N)/2$ modelos, donde N es el número de posibles clases. Esto es, un clasificador decidirá solamente entre dos posibles resultados. Al igual que en el caso anterior, a la hora de realizar una predicción se ejecutan todos los clasificadores y se selecciona aquel que ofrece mayor probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Ecuaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque en primera instancia se puede pensar que para realizar este ejercicio se podría utilizar una regresión lineal en la que la variable dependiente estuviera dicotomizada entre 0 y 1, al modelizar esta recta de regresión, la cual por su naturaleza tiene un dominio $f(x) \\in [-\\infty, +\\infty]$, podríamos encontrar valores/probabilidades por encima de 1 o por debajo de 0 en los valores extremos, lo cual matemáticamente sería incorrecto si estamos tratando de obtener una probabilidad.\n",
    "\n",
    "Para resolver este problema, se le hace una serie de tranformaciones a la ecuación de regresión lineal para que su dominio siempre pertenezca al intervalo $f(x) \\in [0, 1]$. Esta tranformación relaciona el concepto de probabilidad de ocurrencia de un suceso, con la ecuación de la recta.\n",
    "\n",
    "La probabilidad de que ocurra un suceso se define como la razón entre los sucesos favorables y los sucesos totales:\n",
    "\n",
    "\\begin{align}\n",
    "P(y = suceso\\ favorable \\ |\\ x) = \\frac{sucesos\\ favorables}{sucesos\\ totales}\\qquad P \\in [0, 1]\n",
    "\\end{align}\n",
    "\n",
    "La razón de probabilidad (odds ratio) de un suceso favorable se define como el ratio entre la probabilidad del suceso favorable y la probabilidad del suceso desfavorable (1-P):\n",
    "\n",
    "\\begin{align}\n",
    "odds = \\frac{P}{1-P}\\qquad odds \\in [0, +\\infty]\n",
    "\\end{align}\n",
    "\n",
    "Dado que en este momento nos encontramos trabajando en el rango $[0, +\\infty]$, aplicamos a la expresión anterior la función *logit*, que consiste en aplicar el logaritmo natural a la razón de probabilidad. Dado que el logaritmo neperiano de 0 tiene al valor infinito negativo, ya nos encontraríamos en el rango buscado:\n",
    "\n",
    "\\begin{align}\n",
    "ln(odds) = ln\\Bigl(\\frac{P}{1-P}\\Bigr)\\qquad ln(odds) \\in [-\\infty, +\\infty]\n",
    "\\end{align}\n",
    "\n",
    "Una vez tenemos ambas expresiones en el mismo rango $[-\\infty, +\\infty]$, podemos relacionar el log of odds con la ecuación de la regresión lineal:\n",
    "\n",
    "\\begin{align}\n",
    "ln\\Bigl(\\frac{P}{1-P}\\Bigr) = \\beta_0 + \\beta_1 x \\ \\Rightarrow \\ P = \\hat{y} = \\frac{1}{1+e^{-(\\beta_0 + \\beta_1 x)}}\n",
    "\\end{align}\n",
    "\n",
    "Tenemos por lo tanto una predicción que sigue la forma de una función denominada logística o sigmoide. Para esta función, cuando los valores de $x$ son muy grandes, el término $e^{-(\\beta_0 + \\beta_1 x)}$ tiende a 0, por lo que la probabilidad o predicción tenderá a 1; y en caso de que el denominador sea pequeño, la función tenderá a 0.\n",
    "\n",
    "En el caso de trabajar con una regresión logística múltiple el proceso sería muy parecido, solo que el términos $X$ sería una matriz (dimensiones (nxp+1) y $\\beta$ un vector.\n",
    "\n",
    "\\begin{align}\n",
    "P = \\hat{Y} = \\frac{1}{1+e^{-(\\beta_0 + \\sum \\beta_p x_{np})}} = \\frac{1}{1+e^{-(X \\beta)}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Coeficientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se ha definido la ecuación predictora del modelo, es necesario estimar los coeficientes $\\beta_i$. Estos parámetros se pueden obtener mediante el método de la máxima verosimiliutd (ML - Maximum Likelihood) o por el algoritmo del gradiente descendente. En este notebook se explicará el primero de ellos.\n",
    "\n",
    "Según este método se obtienen los estimadores máximos verosímiles como funciones de la muestra que hacen que se maximice la función de verosimilitud asociada a la muestra. Dicho de otro modo, se trata de obtener unos valores estimados de $\\hat{\\beta_i}$ que introducidos en el modelo de predicción $\\hat{y}$, nos den un valor lo más cercano a 1 para aquellos valores del dataset que vienen con valor 1,  y un valor cercano a 0 para aquellos registros del dataset con la variable dependiente igual a 0.\n",
    "\n",
    "El enunciado anterior se puede formalizar usando una ecuación matemática denominada función de verosimilitud (likelihood function):\n",
    "\n",
    "\\begin{align}\n",
    "L(\\beta) = \\prod P(x_i)^{y_i}(1-P(x_i))^{1-y_i}\n",
    "\\end{align}\n",
    "\n",
    "Tomando logaritmos en la expresión anterior para simplificarla y sustituyendo $P(x_i)$:\n",
    "\n",
    "\\begin{align}\n",
    "l = ln(L(\\beta)) = \\sum_{i=1}^{n} -ln(1+e^{X\\beta}) + y_i(\\beta_0 + \\sum_{j=p}^{n} \\beta_j X_{ij})\n",
    "\\end{align}\n",
    "\n",
    "Para buscar los estimadores de máxima verosimilutd se deriva la expresión y se iguala a cero. Para unir las dos expresiones siguientes en una única, se igual el coeficiente $\\alpha$ a uno nuevo denominado $\\beta_0$, y se añade un término nuevo $x_{i0}$ = 1:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial l}{\\partial \\beta_0} = \\sum(y_i - P(x_i)) = 0 \\ ;\\quad\n",
    "\\frac{\\partial l}{\\partial \\beta_j} = \\sum (y_i - P(x_i))x_{ij} = 0\\quad \\rightarrow \\quad\n",
    "\\frac{\\partial l}{\\partial \\beta} = \\sum (y_i - P(x_i))x_{ij} = X· (y_i - P(x_i)) = 0\n",
    "\\end{align}\n",
    "\n",
    "Como el resultado de las derivadas pueden ser una serie de ecuaciones que no tengan una solución sencilla, se puede recurrir al método de Newton-Raphson. Este algoritmo permite encontrar aproximaciones de los ceros o raíces de una función real realizando sucesivas iteraciones.\n",
    "\n",
    "\\begin{align}\n",
    "\\beta_{n+1} = \\beta_n - \\varDelta \\beta \\quad \\rightarrow \\quad\n",
    "\\varDelta \\beta = \\frac{f(\\beta)}{f'(\\beta)} = \\frac{\\frac{\\partial l}{\\partial \\beta}}{\\frac{\\partial^2 l}{\\partial \\beta^2}} = \n",
    "(XWX^T)·(X(y-P_i)) \\quad \\rightarrow \\quad W(\\beta) = diag(P(x_i)(1-P(x_i)))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pseudo-$R^2$:**\n",
    "\n",
    "En los modelos logísticos no existe un indicador de la bondad de los resultados como el $R^2$ que determina la varianza del modelo. Mediante las diferentes funciones estadísticas de paquetes como `statsmodel`, se puede obterner el indicador $pseudo-R^2$. Este indicador nos da una estimación entre 0 y 1 de la precisión del modelo, pero no se puede considerar equivalente al $R^2$.\n",
    "\n",
    "**Matriz de confusión:**\n",
    "\n",
    "Otras formas de evaluar el ajuste del modelo en problemas de clasificación, es mediante las matrices de confusión. En estas matrices se representa el cruce de valores realeas, con valores predecidos y se obtiene el numero de:\n",
    "\n",
    "- true positives (tp)\n",
    "- false positives (fp)\n",
    "- true negatives (tn)\n",
    "- false negatives (fn)\n",
    "\n",
    "De esta matriz, y combinando los términos anteriores, se pueden extraer diferentes ratios:\n",
    "\n",
    "`recall` (TPR/sensitivity) es la capacidad del clasificador para encontrar todas las muestras positivas. Su fórmula es:\n",
    "\n",
    "\\begin{align}\n",
    "recall = \\frac{tp}{tp+fn}\n",
    "\\end{align}\n",
    "\n",
    "`precision` es la capacidad del clasificador de no etiquetar una muestra como positiva si es negativa. Su fórmula es:\n",
    "\n",
    "\\begin{align}\n",
    "precision = \\frac{tp}{tp+fp}\\qquad\n",
    "\\end{align}\n",
    "\n",
    "`specifity` xxxxx. Su fórmula es:\n",
    "\n",
    "\\begin{align}\n",
    "specifity = \\frac{tn}{tn+fp}\\qquad\n",
    "\\end{align}\n",
    "\n",
    "`FPR` false positive rate. Su fórmula es:\n",
    "\n",
    "\\begin{align}\n",
    "FPR = 1 - specifity = \\frac{fp}{tn+fp}\\qquad\n",
    "\\end{align}\n",
    "\n",
    "**Curvas ROC-AUC:**\n",
    "\n",
    "Mediante las curvas ROC-AUC (Receiver Operating Characteristics - Area Under The Curve), también se puede obtener una medida del ajuste del modelo. Estas curvas permiten evaluar como varía la proporción de verdaderos positivos y la de falsos positivos en función de diferentes umbrales (thresholds). Para cada umbral, se obtiene el indicador TPR y FPR, y se grafican en los ejes $x$ e $y$ respectivamente.\n",
    "\n",
    "El gráfico resultante es muy útil para identificar el umbral que consigue un mejor equilibrio sensibilidad-especificidad. Además de esto, la curva ROC, en concreto el área bajo la curva (AUC), puede emplearse como métrica para evaluar modelos. Un modelo que clasifica perfectamente las dos clases tiene un 100% de sensibilidad y especificidad, por lo que el área bajo la curva es de 1. Un modelo que predice por debajo de lo esperado por azar, tiene un AUC menor de 0.5.\n",
    "\n",
    "Atendiendo a la explicación anterior, buscaremos por lo tanto curvas ROC que se encuentren desplazadas hacia la esquina superior izquierda, donde la tasa TPR es mayor que la FPR.\n",
    "\n",
    "\n",
    "**Accuracy y f-measure:**\n",
    "\n",
    "El indicador `accuracy` da un porcentaje del número de aciertos frente al número total de observaciones.\n",
    "\n",
    "\\begin{align}\n",
    "accuracy = \\frac{tp+tn}{total}\n",
    "\\end{align}\n",
    "\n",
    "El indicador `f-score` sirve para comparar modelos que tengan baja `precision` y alto `recall` o viceversa, ya que ayuda a evaluar el desempeño de los modelos teniendo en cuenta ambos indicadores. El `f-score` utilzia la media armónica en vez de la media aritmética, penalizando por tanto los valores extremos. Su fórmula es:\n",
    "\n",
    "\\begin{align}\n",
    "f-score = \\frac{2·recall·precision}{recall+precision}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regresión logística - statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statsmodels es una librería de Python que proporciona clases y funciones para la estimación de muchos modelos estadísticos diferentes, así como para realizar pruebas estadísticas y exploración de datos estadísticos.\n",
    "\n",
    "Este paquete permite obtener datos estadísticos y las bondades de ajuste de una regresión logística y también permite analizar que variables tienen más peso en el ajuste del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio vamos a utilizar un dataset que contiene información de las diferentes campañas de marketing de una entidad bancaria portuguesa, el objetivo es inferir si el cliente se suscribirá o no al producto vendido (variable y - un depósito) en base al resto de datos del fichero.\n",
    "\n",
    "El fichero original tiene información de 41.118 registros, y 21 columnas. Para ahorrar en este notebook toda la parte de limpieza de datos, las variables ya vienen dumificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>...</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>346</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  duration  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0   30       487         2    999         0          -1.8          92.893   \n",
       "1   39       346         4    999         0           1.1          93.994   \n",
       "2   25       227         1    999         0           1.4          94.465   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  ...  month_oct  month_sep  \\\n",
       "0          -46.2      1.313       5099.1  ...          0          0   \n",
       "1          -36.4      4.855       5191.0  ...          0          0   \n",
       "2          -41.8      4.962       5228.1  ...          0          0   \n",
       "\n",
       "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
       "0                1                0                0                0   \n",
       "1                1                0                0                0   \n",
       "2                0                0                0                0   \n",
       "\n",
       "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \n",
       "0                0                 0                     1                 0  \n",
       "1                0                 0                     1                 0  \n",
       "2                1                 0                     1                 0  \n",
       "\n",
       "[3 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cargamos el fichero de trabajo\n",
    "mainpath = \"C:/Users/gmachin/Desktop/Developer/apuntes-notebooks/datasets\"\n",
    "filename = \"/bank/bank.csv\"\n",
    "fullpath = mainpath + filename\n",
    "\n",
    "df_bank = pd.read_csv(fullpath)\n",
    "\n",
    "df_bank.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el dataset cargado, definimos las variables predictoras $X$, y la variable dependiente o a predecir $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Los predictores serán todas las columnas de la tabla menos la columna 'y'\n",
    "X = df_bank.drop(['y'], axis = 1)\n",
    "\n",
    "## En este dataset ya viene la columna a predecir nombrada con la letra 'y'\n",
    "y = df_bank[['y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elección de predictores:**\n",
    "\n",
    "El próximo paso es decidir de entre las 58 variables predictoras que contiene este dataset, cuales tendrán más peso en el modelo. Para ello se emplea la funcion `.RFE` (Recursive Feature Elimination) de la librería `scikit-learn`.\n",
    "\n",
    "La eliminación de características recursivas (RFE) se basa en la idea de construir repetidamente un modelo y elegir las características con mejor o peor desempeño, dejando a un lado una característica y luego repitiendo el proceso con el resto de las características. Este proceso se aplica hasta que se agoten todas las características del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets                             \n",
    "from sklearn.feature_selection import RFE                 ## Importamos la función RFE\n",
    "from sklearn.linear_model import LogisticRegression       ## Importamos modelo de regresión logística\n",
    "\n",
    "## Indicamos número de variables predictoras (libre albedrío)\n",
    "n = 12\n",
    "\n",
    "## Creamos un objeto de regresión logística\n",
    "lr = LogisticRegression()\n",
    "\n",
    "## Creamos un objeto rfe e indicamos como parámetros que es una regresión logística, y el número de predictores\n",
    "rfe = RFE(lr, n)\n",
    "\n",
    "## Alimentamos el modelo rfe con los valores de X y de y para entrenarlo\n",
    "rfe = rfe.fit(X, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la función `.support_` del objeto `rfe` creado, se puede obtener que predictores son los mejores para realizar la regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True False False False  True False False False\n",
      "  True False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True  True  True  True  True False\n",
      "  True False False False False False False  True False  True]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede obtener el ranking de los mejores predictores mediante la función `.ranking_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34 40 18 42  1 14 27 25  1 38 22  3  1 35  2 36  1  5 30 33 12 45 19 39\n",
      " 31 47 26 13 46 21 32  8 20  6 10 15  9 23 16  4 43 24  1  1  1  1  1 17\n",
      "  1 44 37 28 41 29 11  1  7  1]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver definitivamente que columnas se van a utilizar, podemos juntar las 3 listas anteriores: nombre de las columnas, resultado de la función `.support_` y resultado de la función `.ranking_`. Aquellas que tengan el valor True y el número 1 serán las incluídas en el modelo como predictores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', False, 34),\n",
       " ('duration', False, 40),\n",
       " ('campaign', False, 18),\n",
       " ('pdays', False, 42),\n",
       " ('previous', True, 1),\n",
       " ('emp.var.rate', False, 14),\n",
       " ('cons.price.idx', False, 27),\n",
       " ('cons.conf.idx', False, 25),\n",
       " ('euribor3m', True, 1),\n",
       " ('nr.employed', False, 38),\n",
       " ('y', False, 22),\n",
       " ('job_admin.', False, 3),\n",
       " ('job_blue-collar', True, 1),\n",
       " ('job_entrepreneur', False, 35),\n",
       " ('job_housemaid', False, 2),\n",
       " ('job_management', False, 36),\n",
       " ('job_retired', True, 1),\n",
       " ('job_self-employed', False, 5),\n",
       " ('job_services', False, 30),\n",
       " ('job_student', False, 33),\n",
       " ('job_technician', False, 12),\n",
       " ('job_unemployed', False, 45),\n",
       " ('job_unknown', False, 19),\n",
       " ('marital_divorced', False, 39),\n",
       " ('marital_married', False, 31),\n",
       " ('marital_single', False, 47),\n",
       " ('marital_unknown', False, 26),\n",
       " ('education_Basic', False, 13),\n",
       " ('education_High School', False, 46),\n",
       " ('education_Illiterate', False, 21),\n",
       " ('education_Professional Course', False, 32),\n",
       " ('education_University Degree', False, 8),\n",
       " ('education_Unknown', False, 20),\n",
       " ('housing_no', False, 6),\n",
       " ('housing_unknown', False, 10),\n",
       " ('housing_yes', False, 15),\n",
       " ('loan_no', False, 9),\n",
       " ('loan_unknown', False, 23),\n",
       " ('loan_yes', False, 16),\n",
       " ('contact_cellular', False, 4),\n",
       " ('contact_telephone', False, 43),\n",
       " ('month_apr', False, 24),\n",
       " ('month_aug', True, 1),\n",
       " ('month_dec', True, 1),\n",
       " ('month_jul', True, 1),\n",
       " ('month_jun', True, 1),\n",
       " ('month_mar', True, 1),\n",
       " ('month_may', False, 17),\n",
       " ('month_nov', True, 1),\n",
       " ('month_oct', False, 44),\n",
       " ('month_sep', False, 37),\n",
       " ('day_of_week_fri', False, 28),\n",
       " ('day_of_week_mon', False, 41),\n",
       " ('day_of_week_thu', False, 29),\n",
       " ('day_of_week_tue', False, 11),\n",
       " ('day_of_week_wed', True, 1),\n",
       " ('poutcome_failure', False, 7),\n",
       " ('poutcome_nonexistent', True, 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank_vars = df_bank.columns.values.tolist()\n",
    "z = zip(df_bank_vars, rfe.support_, rfe.ranking_)\n",
    "\n",
    "list(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creamos una lista con todas las columnas con valor True del modelo RFE\n",
    "cols = [\"previous\", \"euribor3m\", \"job_blue-collar\", \"job_retired\", \"month_aug\", \"month_dec\", \n",
    "        \"month_jul\", \"month_jun\", \"month_mar\", \"month_nov\", \"day_of_week_wed\", \"poutcome_nonexistent\"]\n",
    "\n",
    "X = df_bank[cols]\n",
    "y = df_bank[[\"y\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de regresión logística múltiple:**\n",
    "\n",
    "Mediante la función `sm.Logit(output, inputs).fit()` de `statsmodel`, se puede obtener el modelo de regresión logística de una variable dependiente $y$ frente a las variables independientes $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.291770\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de los coeficientes:**\n",
    "\n",
    "Una vez se ha creado el modelo, se puede obtener el valor de cada parámetro $\\beta$ mediante la función `.params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "previous               -0.122862\n",
       "euribor3m              -0.604899\n",
       "job_blue-collar        -0.503233\n",
       "job_retired             0.223547\n",
       "month_aug               0.604806\n",
       "month_dec               1.135775\n",
       "month_jul               1.032700\n",
       "month_jun               1.077547\n",
       "month_mar               1.644831\n",
       "month_nov               0.382789\n",
       "day_of_week_wed        -0.064885\n",
       "poutcome_nonexistent   -0.775330\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto en temas anteriores, estos coeficientes son estimados, y por lo tanto debemos calcular su p-valor para ver si estos parámetros tienen significancia estadística. Marcamos como nivel de significancia válido 0.05.\n",
    "\n",
    "Se pueden obtener los p-valores mediante la función `.pvalues`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "previous                7.934286e-02\n",
       "euribor3m               3.749001e-56\n",
       "job_blue-collar         9.209968e-04\n",
       "job_retired             3.074857e-01\n",
       "month_aug               5.872384e-04\n",
       "month_dec               1.146942e-02\n",
       "month_jul               6.406993e-08\n",
       "month_jun               7.784547e-10\n",
       "month_mar               1.599367e-07\n",
       "month_nov               4.959867e-02\n",
       "day_of_week_wed         6.408835e-01\n",
       "poutcome_nonexistent    2.164260e-10\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo:**\n",
    "\n",
    "Por último se puede presentar un cuadro resumen de todos los indicadores y valores estadísticos del modelo mediante la función `.summary()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>  4119</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  4107</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 19 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1554</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:57:13</td>     <th>  Log-Likelihood:    </th> <td> -1201.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1422.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>6.449e-88</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous</th>             <td>   -0.1229</td> <td>    0.070</td> <td>   -1.755</td> <td> 0.079</td> <td>   -0.260</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>euribor3m</th>            <td>   -0.6049</td> <td>    0.038</td> <td>  -15.788</td> <td> 0.000</td> <td>   -0.680</td> <td>   -0.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>job_blue-collar</th>      <td>   -0.5032</td> <td>    0.152</td> <td>   -3.314</td> <td> 0.001</td> <td>   -0.801</td> <td>   -0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>job_retired</th>          <td>    0.2235</td> <td>    0.219</td> <td>    1.021</td> <td> 0.307</td> <td>   -0.206</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_aug</th>            <td>    0.6048</td> <td>    0.176</td> <td>    3.437</td> <td> 0.001</td> <td>    0.260</td> <td>    0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_dec</th>            <td>    1.1358</td> <td>    0.449</td> <td>    2.528</td> <td> 0.011</td> <td>    0.255</td> <td>    2.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_jul</th>            <td>    1.0327</td> <td>    0.191</td> <td>    5.407</td> <td> 0.000</td> <td>    0.658</td> <td>    1.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_jun</th>            <td>    1.0775</td> <td>    0.175</td> <td>    6.149</td> <td> 0.000</td> <td>    0.734</td> <td>    1.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_mar</th>            <td>    1.6448</td> <td>    0.314</td> <td>    5.241</td> <td> 0.000</td> <td>    1.030</td> <td>    2.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_nov</th>            <td>    0.3828</td> <td>    0.195</td> <td>    1.963</td> <td> 0.050</td> <td>    0.001</td> <td>    0.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day_of_week_wed</th>      <td>   -0.0649</td> <td>    0.139</td> <td>   -0.466</td> <td> 0.641</td> <td>   -0.338</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poutcome_nonexistent</th> <td>   -0.7753</td> <td>    0.122</td> <td>   -6.349</td> <td> 0.000</td> <td>   -1.015</td> <td>   -0.536</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 4119\n",
       "Model:                          Logit   Df Residuals:                     4107\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Tue, 19 May 2020   Pseudo R-squ.:                  0.1554\n",
       "Time:                        19:57:13   Log-Likelihood:                -1201.8\n",
       "converged:                       True   LL-Null:                       -1422.9\n",
       "Covariance Type:            nonrobust   LLR p-value:                 6.449e-88\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "previous                -0.1229      0.070     -1.755      0.079      -0.260       0.014\n",
       "euribor3m               -0.6049      0.038    -15.788      0.000      -0.680      -0.530\n",
       "job_blue-collar         -0.5032      0.152     -3.314      0.001      -0.801      -0.206\n",
       "job_retired              0.2235      0.219      1.021      0.307      -0.206       0.653\n",
       "month_aug                0.6048      0.176      3.437      0.001       0.260       0.950\n",
       "month_dec                1.1358      0.449      2.528      0.011       0.255       2.016\n",
       "month_jul                1.0327      0.191      5.407      0.000       0.658       1.407\n",
       "month_jun                1.0775      0.175      6.149      0.000       0.734       1.421\n",
       "month_mar                1.6448      0.314      5.241      0.000       1.030       2.260\n",
       "month_nov                0.3828      0.195      1.963      0.050       0.001       0.765\n",
       "day_of_week_wed         -0.0649      0.139     -0.466      0.641      -0.338       0.208\n",
       "poutcome_nonexistent    -0.7753      0.122     -6.349      0.000      -1.015      -0.536\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si analizamos los p-valores, encontramos que existen 4 parámetros cuyo valor supera el 0.05, por lo que podríamos eliminarlos del modelo por no tener significancia estadística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se ha dado por bueno el modelo de predicción obtenido, también se pueden obtener las variables dependientes $\\hat{y}_i$ a partir de las variables independientes $X$ mediante la función `lm.predict(pd.DataFrame(inputs))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regresión logística - scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` es una libreria de aprendizaje automático de software libre para el lenguaje de programación Python. Incluye algoritmos de clasificación, regresión y clustering.\n",
    "\n",
    "Al igual que el paquete `statsmodel`, esta librería contiene ya funciones predefinidas que permiten realizar una regresión logística de forma sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos librerias\n",
    "from sklearn.linear_model import LogisticRegression              ## Módulo para realizar regresiones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de regresión lineal múltiple:**\n",
    "\n",
    "Para fabricar el módelo de regresión mediante la libreria `scikit-learn` en primer lugar se debe crear un objeto de regresión logística mediante la función `LogisticRegression()`, para después entrenarlo con el dataset `.fit(inputs, outputs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crear un objeto de regresión lineal, lo llamamos logit_model:\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "## Entrenamiento del modelo mediante el dataset:\n",
    "logit_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de los coeficientes:**\n",
    "\n",
    "Una vez se ha entrenado el modelo, se pueden extraer los coeficientes \\beta mediante la función `.coef_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50765714, -0.54649613, -0.35915536,  0.35603839,  0.62539831,\n",
       "         1.1822173 ,  0.96226336,  1.05431792,  1.63063663,  0.45195768,\n",
       "         0.04171434,  0.30569877]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *El valor de los coeficientes puede variar ligeramente si se comparan con los obtenidos a partir de la librería `statsmodel`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo:**\n",
    "\n",
    "Podemos obtener el indicador de precisión del modelo mediante la función `lm.score(inputs, outputs)`. Este indicador lo que comprueba es si el valor predecido es igual o no a la variable dependiente, y muestra el porcentaje de acierto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963340616654528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se ha dado por bueno el modelo de predicción obtenido, también se pueden obtener las variables dependientes $\\hat{y}_i$ a partir de las variables independientes $x_i$ mediante la función `.predict(inputs)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo - conjuntos de test y entrenamiento:**\n",
    "\n",
    "Aunque en los puntos anteriores hemos obtenido los coeficientes y bondad de ajuste del modelo a partir de todo el conjunto de datos, los normal es dividir el fichero en dos subconjuntos. El primero de ellos será para el entrenamiento del modelo y suele ser de entre el 70-80% del dataset, y dejar el resto para testear el modelo.\n",
    "\n",
    "Este método evita los problemas de overfitting que se darían si utilizasemos todo el dataset como conjunto de entrenamiento.\n",
    "\n",
    "Para dividir un dataset en conjunto de test y en conjunto de entrenamiento, podemos utilizar la función `.train_test_split(inputs, outputs, test_size, random_state)` de la librería `scikit-learn`.\n",
    "\n",
    "- `inputs`: variables predictoras\n",
    "- `outputs`: variable dependiente\n",
    "- `test_size`: % del dataset que se va a utilizar como subconjunto de test\n",
    "- `random_state`: seed de los número aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos la función train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Indicamos que queremos un subconjunto de test de un 30%, y una semilla con valor 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "## Crear un objeto de regresión lineal, lo llamamos logit_model:\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "## Entrenamiento del modelo mediante el dataset de entrenamiento:\n",
    "logit_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el modelo entrenado, podemos obtener la bondad de ajuste del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004854368932039"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importamos la función metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "## Realizamos la predicción a partir de las variables de test\n",
    "prediction = logit_model.predict(X_test)\n",
    "\n",
    "## Evaluamos la precisión para el subconjunto de test\n",
    "metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo - validación cruzada:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada (cross validation) es una técnica utilizada para evaluar los resultados del análisis estadístico son independientes de las particiones entre subconjuntos de test y entrenamiento.\n",
    "\n",
    "Esta técnica divide un dataset en subconjunto de test y entrenamiento de k-formas diferentes, y para cada una de estas formas calcula todos los parámetros. Por último se hace la media aritmética de los parámetros de cada validación, y se obtiene una media de los datos. Este método disminuye errores en la estimación de parámetros de cada modelo, y minimiza otras casuísticas como el overfitting.\n",
    "\n",
    "Dentro del método de validación cruzada, en función del número k en el que dividamos el dataset podemos definir 3 métodos:\n",
    "\n",
    "- k = 1: validación cruzada simple\n",
    "- k = 5-10: K-fold cross validation\n",
    "- k = n: Leave One Out Cross Validation (LOOCV)\n",
    "\n",
    "En función del valor de k, podremos experimentar una compensación del sesgo-varianza, teniendo para valores de k muy elevadas, modelos con un sesgo bajo pero con una varianza muy elevada, es decir overfitting. En bibliografía de referencia como *An Introduction to Statistical Learning*, se recomienda utilizar el método k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos la función cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## Dividimos el dataset en 10 folders\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring = \"accuracy\", cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9031477 , 0.88834951, 0.90533981, 0.89563107, 0.90048544,\n",
       "       0.8907767 , 0.88349515, 0.89320388, 0.89537713, 0.88807786])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Obtenemos el score de cada folder\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8943884240990478"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de la precisión del modelo - matriz de confusión y curvas ROC:**\n",
    "\n",
    "Como se comentaba al inicio del notebook, otra forma de evaluar el desempeño del modelo era mediante las matrices de confusión de donde se obtienen los valores de true positive, false positive...etc; y las curvas ROC-AUC, las cuales se basan en los indicadores anteriores.\n",
    "\n",
    "Dentro de la libreria `scikit-learn` podemos encontrar sublibrerías como `metrics` que nos permiten obtener todos los indicadores que se vieron al principio del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos la función train_test_split y classification_report\n",
    "from sklearn.linear_model import LogisticRegression   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "## Indicamos que queremos un subconjunto de test de un 30%, y una semilla con valor 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "## Crear un objeto de regresión lineal, lo llamamos logit_model:\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "## Entrenamiento del modelo mediante el dataset de entrenamiento:\n",
    "logit_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Realizamos una predicción de y en base a las X_test\n",
    "y_pred = logit_model.predict(X_test)\n",
    "\n",
    "## Realizamos una predicción de la probabilidad de que y pertenezca a una clasificación en base a las X_test\n",
    "y_pred_prob = logit_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión e indicadores asociados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1099   15]\n",
      " [ 108   14]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predicted label')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix), annot = True, cmap = \"YlGnBu\", fmt = 'g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y = 1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener los indicadores `precision`, `recall`, `accuracy` y `f-score` vistos en el primer punto de este notebook, mediante la funcion `classification_report(y_test, y_pred)`, o cada uno por separado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      1114\n",
      "           1       0.48      0.11      0.19       122\n",
      "\n",
      "    accuracy                           0.90      1236\n",
      "   macro avg       0.70      0.55      0.57      1236\n",
      "weighted avg       0.87      0.90      0.87      1236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.4827586206896552\n",
      "Exactitud del modelo: 0.9004854368932039\n",
      "Sensibilidad del modelo: 0.11475409836065574\n",
      "Puntaje F1 del modelo: 0.18543046357615894\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "exactitud = metrics.accuracy_score(y_test, y_pred)\n",
    "sensibilidad = metrics.recall_score(y_test, y_pred)\n",
    "puntajef1 = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "print('Precisión del modelo:', precision)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "print('Sensibilidad del modelo:', sensibilidad)\n",
    "print('Puntaje F1 del modelo:', puntajef1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curvas ROC-AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curva ROC - AUC del modelo:\n",
      "0.5506445536686582\n"
     ]
    }
   ],
   "source": [
    "## Importamos librerías\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Calculo la curva ROC - AUC del modelo\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print('Curva ROC - AUC del modelo:')\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Graficamos la curva\n",
    "logit_roc_auc = roc_auc_score(y_test, logit_model.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logit_model.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label = 'Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
